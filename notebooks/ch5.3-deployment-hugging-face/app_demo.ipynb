{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ead702-8a89-4c45-bd2b-b939b0c62f60",
   "metadata": {},
   "source": [
    "# Model Deployment with Gradio and Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad13e8-928a-4b77-a990-3d280ce90c5a",
   "metadata": {},
   "source": [
    "- We trained our model and say we are happy about its performance. We may want to introduce it community so that everyone can use it, preferably via their phones. This is called *deployment*. \n",
    "\n",
    "- Core idea is that users will take or upload their sneaker pictures to a server and we will pass the image through our model and present the results back to the user in a user-friendly manner. One of the most popular tools to achive this is **gradio**. \n",
    "\n",
    "- Once we have the best Pytorch model, all we need is a function,*get_class_probs*, that can accept the image and return the predictions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097f69c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22339,
     "status": "ok",
     "timestamp": 1682968184541,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "097f69c4",
    "outputId": "3efb494f-62dd-47f9-9d7b-3a0e26b2c171"
   },
   "outputs": [],
   "source": [
    "!pip install gradio timm -q\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065d0efd",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682968184541,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "065d0efd"
   },
   "outputs": [],
   "source": [
    "idx_to_class = {0: 'adidas', 1: 'converse', 2: 'new-balance', 3: 'nike', 4: 'reebok', 5: 'vans'}\n",
    "num_classes = len(idx_to_class)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std =  [0.229, 0.224, 0.225]\n",
    "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean,std)\n",
    "                                     ])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5105de",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682968184542,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "6a5105de"
   },
   "outputs": [],
   "source": [
    "def get_model(model_name = 'efficientnet_b0',freeze = False):\n",
    "    model = timm.create_model(model_name = model_name,pretrained=True)\n",
    "    if freeze:\n",
    "        for parameter in model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "    \n",
    "    in_features = model.classifier.in_features # 1792\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "                          nn.Linear(in_features, 100), \n",
    "                          nn.BatchNorm1d(num_features=100),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(),\n",
    "                          nn.Linear(100, num_classes),\n",
    "                                    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b473e8c",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682968184542,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "0b473e8c"
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    checkpoint = torch.load(model_path,map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.best_scores = checkpoint['best_stats']\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b3fd21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1673,
     "status": "ok",
     "timestamp": 1682968186868,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "40b3fd21",
    "outputId": "63bcfb6d-d9ca-4cb2-b27a-9d78cfd3bb1f"
   },
   "outputs": [],
   "source": [
    "model = load_model(get_model(),\"snicker_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2bc9b7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1682968189056,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "bc2bc9b7"
   },
   "outputs": [],
   "source": [
    "def get_class_probs(img):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        img = test_transforms(img)\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        output = model(img)\n",
    "        # remember softmax\n",
    "        probs = F.softmax(output,dim=1)\n",
    "        probs, indices = probs.topk(k=num_classes)\n",
    "        probs = probs[0].tolist()\n",
    "        indices = indices[0].tolist()\n",
    "        classes = [idx_to_class[index] for index in indices]\n",
    "        confidences = {classes[i]: round(probs[i],3) for i in range(num_classes)}  \n",
    "\n",
    "    return confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e070f2a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 4448,
     "status": "ok",
     "timestamp": 1682968195732,
     "user": {
      "displayName": "Erdi",
      "userId": "00321255967831130197"
     },
     "user_tz": 240
    },
    "id": "e070f2a7",
    "outputId": "6430b18c-852f-40ef-cf9e-2d2cb6fcb693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://f4623906-a7cb-41b7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f4623906-a7cb-41b7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\"samples/a.jpeg\",\"samples/c.jpeg\",\"samples/r.jpeg\"]\n",
    "gr.Interface(fn=get_class_probs, \n",
    "             inputs=gr.Image(type=\"pil\",source=\"upload\"),\n",
    "             outputs=gr.Label(num_top_classes=6),\n",
    "             examples=examples).launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bfec3-fb19-4f2b-b836-12a8c51f5e64",
   "metadata": {
    "id": "1f9eeb29"
   },
   "source": [
    "- As you see from the message above, the link we create expires in 72 hours. If you need a permenant deployment, you can use [HuggingFace](https://huggingface.co/). If you want to be an AI practioner, this is one of the must spaces you should discover. \n",
    "\n",
    "- All we need is to create an account and upload eveything in this folder. \"app.py\" is just a naive Python file of this jupyter file. Huggingface system will compile it and create your app automatically. I already did it. Here is the permanent link\n",
    "\n",
    "\n",
    "https://huggingface.co/spaces/erdi28/sneaker-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab64d9",
   "metadata": {
    "id": "5fab64d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b0fb5",
   "metadata": {
    "id": "cf1b0fb5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d10d0",
   "metadata": {
    "id": "f88d10d0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
